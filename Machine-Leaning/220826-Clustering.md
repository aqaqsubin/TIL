# **Clustering**

- **Partitioning method**
- Hierarchical method
- **Density-based method**
- Grid-based method
- **Model-based method**

<br>

## **Partitioning Method**

$n$ê°œì˜ data pointë“¤ì´ ìˆì„ ë•Œ, ì‚¬ìš©ìì— ì˜í•´ ì •ì˜ëœ $k$ê°œì˜ ê·¸ë£¹ìœ¼ë¡œ êµ°ì§‘í™”í•˜ëŠ” ë°©ë²•

- K-meansì™€ K-medoidê°€ ìˆë‹¤.

> *Partitioning methods define clusters by grouping data points into k partitions, defined by the user at the time the process is executed.*
> 


### **1. K-means**

clusterì˜ centroidì™€ì˜ ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ë¥¼ ìµœì†Œí™”í•˜ëŠ” ì‘ì—…ì„ ë°˜ë³µí•¨ìœ¼ë¡œì¨ ë¶„ë¥˜í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ë¹„ì§€ë„ í•™ìŠµ ê¸°ë²•ì´ë‹¤.

**K-means ë™ì‘ ë‹¨ê³„**

![Untitled](../img/Machine-Learning/kmeans.png)

1. $k$ê°œì˜ ì„ì˜ì˜ ì¤‘ì‹¬ì (centroid) ë°°ì¹˜ (ì´ˆê¸° ê°’ì— ë”°ë¥¸ ì‹¤íŒ¨ ê°€ëŠ¥ì„± æœ‰)
2. ê° ë°ì´í„°ë“¤ì„ ê°€ì¥ ê°€ê¹Œìš´ ì¤‘ì‹¬ì ìœ¼ë¡œ í• ë‹¹
3. ê° clusterì˜ centroidë¥¼ cluster ë‚´ data pointì˜ í‰ê·  ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸
4. ë” ì´ìƒ centroidê°€ ê°±ì‹ ë˜ì§€ ì•Šì„ ë•Œê¹Œì§€ 2-3 ë°˜ë³µ

> ğŸ’¡ **K-means: Procs and Cons**
>
> - ì„ í˜• ì‹œê°„ ë‚´ì— **ë¹ ë¥´ê²Œ ë™ì‘**í•¨
> - ëœë¤í•˜ê²Œ ì„¤ì •ëœ **ì´ˆê¸° ê°’ì— ë”°ë¼ local optima**ì— ë¹ ì§ˆ ìˆ˜ ìˆìŒ
> - ì ì ˆí•œ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ë¥¼ ì‚¬ìš©ìê°€ ì§€ì •í•´ì•¼ í•¨
> - Outlierì— ë¯¼ê°í•¨
> - ë°ì´í„° ë°€ë„, ë¶„í¬ í˜•íƒœ, í¬ê¸°ê°€ ë‹¤ì–‘í•œ ê²½ìš°, ì‹¤íŒ¨ ê°€ëŠ¥ì„±ì´ ì»¤ì§

<br>

>âš ï¸ **Partitioning methodì˜ í•œê³„**
>
> Partitioning methodëŠ” data point ê°„ì˜ ê±°ë¦¬ì— ê¸°ì´ˆí•˜ì—¬ êµ°ì§‘í™”
>
>â†’ ì˜¤ì§ **êµ¬í˜•ì˜ cluster** ë§Œì„ ì°¾ì„ ìˆ˜ ìˆê³ , ì„ì˜ì˜ í˜•íƒœì˜ clusterë¥¼ ì°¾ëŠ” ë° ì–´ë ¤ì›€

---


## **Density-based Method**

Density-based methodëŠ” **data point ë°€ë„** ì— ë”°ë¼ êµ°ì§‘í™”

â†’  ë°€ë„ê°€ ë‚®ì€ ì˜ì—­ì„ ì¡ìŒ ì˜ì—­ìœ¼ë¡œ ë¶„ë¦¬, data pointê°€ ì¡°ë°€í•œ ì˜ì—­ì„ clusterë¡œ ì—¬ê¹€


> ğŸ“Œ **ì •ì˜**
> 
> Directly density reachable
> 
> Density reachable
> 
> Density connected
> 
> Cluster

<br>

### **DBSCAN (Density-Based Spatial Clustering of Applicatioins with Noise)**


>ğŸ’¡ **DBSCAN: Procs and Cons**
>
> - ì‚¬ìš©ìê°€ í´ëŸ¬ìŠ¤ì˜ ê°œìˆ˜ë¥¼ ì§€ì •í•  í•„ìš” ì—†ìŒ
> - **ë‹¤ì–‘í•œ shape**ì— ê°•ê±´í•¨
> - Outlierë¥¼ êµ¬ë¶„í•˜ê¸° ë•Œë¬¸ì— **ë…¸ì´ì¦ˆì— ê°•ê±´**í•¨
> 
> - ë°ì´í„° ë¶„í¬ê°€ ë‹¤ì–‘í•œ ë°€ë„ë¥¼ ê°€ì§„ ê²½ìš°, ì‹¤íŒ¨ ê°€ëŠ¥ì„±ì´ ì»¤ì§
> - Eps, minPtsì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì •í•´ì•¼ í•¨
> - Eps ë°˜ê²½ ì´ë‚´ì¸ì§€ ë¹„êµ ì—°ì‹ ì‹œê°„ì´ $n\log n$

---

## **Model-based method**

$k$ë²ˆì§¸ clusterì— ì†í•œ ê´€ì¸¡ì¹˜ $x$ê°€ ë‹¤ë³€ëŸ‰ ì •ê·œë¶„í¬ì¸ í™•ë¥  ë°€ë„ í•¨ìˆ˜ $f$ë¥¼ ê°€ì§„ë‹¤ê³  ê°€ì •í•œë‹¤.

â‡’ ê´€ì°°ëœ data pointëŠ” ê° clusterì— ì†í•  í™•ë¥  ë¶„í¬ë¥¼ í˜¼í•©í•œ í˜¼í•© ë¶„í¬ë¥¼ ê°€ì§„ë‹¤

**ë‹¤ë³€ëŸ‰ ë¶„í¬(Multi-variable Distribution)** : í™•ë¥  ë³€ìˆ˜ê°€ í•˜ë‚˜ ì´ìƒì¸ ë¶„í¬

data point $x$ê°€ ì£¼ì–´ì§€ë©´, ê° clusterì— ì†í•  ì‚¬í›„ í™•ë¥  (ë˜ëŠ” Likelihood)ì„ ê³„ì‚°í•˜ì—¬ 
ê°€ì¥ ë†’ì€ í™•ë¥ (ë˜ëŠ” Likelihood)ì˜ clusterë¡œ í• ë‹¹í•œë‹¤. (**MAPì™€ MLE**)

~ EMê³¼ GMMì´ ìˆë‹¤.


> ğŸ“¢ **MLEì™€ MAP**
>
>ë™ì „ì˜ ì•ë©´ $H$ê°€ ë‚˜ì˜¬ í™•ë¥ ì´ $\theta$ì¼ ë•Œ, ì•ë©´ì´ ë‚˜ì˜¬ í™•ë¥ ì€ ì–´ë–»ê²Œ êµ¬í• ê¹Œ
>
> **1) Maximum Likelihood Estimation(MLE)**
>
> â†’ **Likelihoodë¥¼ ìµœëŒ€ë¡œ í•˜ëŠ” ìµœì ì˜ í™•ë¥ **
> 
> : í™•ë¥  ì§ˆëŸ‰ í•¨ìˆ˜(ë˜ëŠ” í™•ë¥  ë°€ë„ í•¨ìˆ˜)ì—ì„œ **ê´€ì¸¡ëœ í‘œë³¸**ì—ì„œ $\theta$ë¥¼ ì¶”ì²­í•˜ëŠ” ë°©ë²•
> 
> $`P(D|\theta) = \theta^{a_H}(1-\theta)^{a_T}`$ *â†’ $a_H$ ê³¼ $a_T$ëŠ” ê°ê° ì•ë©´ê³¼ ë’·ë©´ì´ ë‚˜ì˜¨ íšŸìˆ˜*
> 
> $`\hat{\theta} = argmax_{\theta}P(D|\theta)`$
> 
> ~ $P(D|\theta)$ëŠ” $\theta$ê°€ ì£¼ì–´ì¡Œì„ ë•Œì˜ $D$ì˜ ë¶„í¬ë¡œ, $\theta$ì˜ ë¶„í¬
> 
> ~ ìµœì ì˜ $\theta$ ê°’ì¸ $\hat{\theta}$ëŠ” ê·¸ë˜í”„ **ë¯¸ë¶„**ì„ í†µí•´ í•¨ìˆ˜ì˜ ìµœëŒ“ê°’ì„ ì°¾ì•„ êµ¬í•¨
> 
> <br>
>
>**2) Maximum a Posteriori Estimation(MAP)**
>
>â†’ **Posteriorë¥¼ ìµœëŒ€ë¡œ í•˜ëŠ” ìµœì ì˜ í™•ë¥ **
>
>: **ë² ì´ì¦ˆ ì •ë¦¬** ë¥¼ í™œìš©í•˜ì—¬ Posteriorë¥¼ ê³„ì‚°
>
>$`P(\theta|D) = \frac{P(D|\theta)P(\theta)}{P(D)}`$
>
>$`\hat{\theta} = argmax_{\theta}P(\theta|D)`$
>
>~ $P(\theta|D)$ëŠ” ë°ì´í„° $D$ê°€ ì£¼ì–´ì¡Œì„ ë•Œì˜ $\theta$ì˜ ë¶„í¬ë¡œ, ë°ì´í„° ë¶„í¬ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤
>
><br>
>
>**3) MLE vs MAP**  
>ë°ì´í„°ê°€ ë§ë‹¤ë©´ ë¹„ìŠ·í•˜ì§€ë§Œ, ë°ì´í„°ê°€ ì ë‹¤ë©´ ì‚¬ì „ ì§€ì‹ì„ í™œìš©í•œ MAPê°€ ë” ìœ ìš©í•˜ë‹¤

<br>

### EM (Expectation Maximization)

### GMM (Gaussian Mixture Modeling)

<br>

> ğŸ“Œ **K-means vs DBSCAN**
